{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Logistic Regression\n",
    "Creation of the logistic regression model for Iris to perform multiclass classification on all the attributes of the set.\n",
    "\n",
    "- Carrying out the definition of the architecture using both the high and medium level interfaces.\n",
    "- Multiclass accuracy programming and evaluate the model with this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd60785c710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from itertools import islice as take\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "URL = 'https://raw.githubusercontent.com/gibranfp/CursoAprendizajeProfundo/master/data/iris/iris.csv'\n",
    "base_dir = './data/iris/'\n",
    "filename = 'iris.csv'\n",
    "filepath = os.path.join(base_dir, 'iris.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will use a reference set called Iris collected by Ronald Fisher (yes, the same one from the Fisher-Yates shuffling algorithm). This set has four input attributes: the widths and lengths of the petals and sepals; Ytres clases de flor iris de salida: setosa, versicolour, virginica.\n",
    "\n",
    "![Pétalo y sépalo](https://miro.medium.com/max/2550/1*7bnLKsChXq94QjtAiRn40w.png)\n",
    "<center>Fuente: Suruchi Fialoke, October 13, 2016, Classification of Iris Varieties</center>\n",
    "\n",
    "This set has 50 samples of each class, let's read it and print the first five of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and codification of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/iris/iris.csv\n",
      "(150, 4)\n",
      "(150,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm Species\n",
       "1              4.9           3.0            1.4           0.2       0\n",
       "2              4.7           3.2            1.3           0.2       0\n",
       "3              4.6           3.1            1.5           0.2       0\n",
       "4              5.0           3.6            1.4           0.2       0\n",
       "50             7.0           3.2            4.7           1.4       1\n",
       "51             6.4           3.2            4.5           1.5       1\n",
       "52             6.9           3.1            4.9           1.5       1\n",
       "53             5.5           2.3            4.0           1.3       1\n",
       "54             6.5           2.8            4.6           1.5       1\n",
       "100            6.3           3.3            6.0           2.5       2\n",
       "101            5.8           2.7            5.1           1.9       2\n",
       "102            7.1           3.0            5.9           2.1       2\n",
       "103            6.3           2.9            5.6           1.8       2\n",
       "104            6.5           3.0            5.8           2.2       2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_url(URL, base_dir, filename)\n",
    "columns = ('SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species')\n",
    "df = pd.read_csv('./data/iris/iris.csv', names=columns)\n",
    "df.loc[df.Species=='Iris-setosa', 'Species'] = 0\n",
    "df.loc[df.Species=='Iris-versicolor', 'Species'] = 1\n",
    "df.loc[df.Species=='Iris-virginica', 'Species'] = 2\n",
    "x_trn = np.array(df.iloc[:,:4], dtype=\"float32\")\n",
    "y_trn = np.array(df.iloc[:, -1], dtype=\"float32\")\n",
    "print(x_trn.shape)\n",
    "print(y_trn.shape)\n",
    "pd.concat((df[1:5], df[50:55], df[100:105]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data / Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train,features_test, labels_train, labels_test = train_test_split(x_trn, y_trn, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionLogisticaMulticlase(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegresionLogisticaMulticlase, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,50)\n",
    "        self.layer2 = nn.Linear(50, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.layer1(x))\n",
    "        x = F.softmax(self.layer2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca # 1\n",
      "El valor de la función de perdida es:  109.1550350189209\n",
      "Epoca # 2\n",
      "El valor de la función de perdida es:  108.1132173538208\n",
      "Epoca # 3\n",
      "El valor de la función de perdida es:  107.10022449493408\n",
      "Epoca # 4\n",
      "El valor de la función de perdida es:  106.00082874298096\n",
      "Epoca # 5\n",
      "El valor de la función de perdida es:  104.80237007141113\n",
      "Epoca # 6\n",
      "El valor de la función de perdida es:  103.5280704498291\n",
      "Epoca # 7\n",
      "El valor de la función de perdida es:  102.21449136734009\n",
      "Epoca # 8\n",
      "El valor de la función de perdida es:  100.87023973464966\n",
      "Epoca # 9\n",
      "El valor de la función de perdida es:  99.47323203086853\n",
      "Epoca # 10\n",
      "El valor de la función de perdida es:  98.02560806274414\n",
      "Epoca # 11\n",
      "El valor de la función de perdida es:  96.5609610080719\n",
      "Epoca # 12\n",
      "El valor de la función de perdida es:  95.11640667915344\n",
      "Epoca # 13\n",
      "El valor de la función de perdida es:  93.71005296707153\n",
      "Epoca # 14\n",
      "El valor de la función de perdida es:  92.34743118286133\n",
      "Epoca # 15\n",
      "El valor de la función de perdida es:  91.03881120681763\n",
      "Epoca # 16\n",
      "El valor de la función de perdida es:  89.79889154434204\n",
      "Epoca # 17\n",
      "El valor de la función de perdida es:  88.63586187362671\n",
      "Epoca # 18\n",
      "El valor de la función de perdida es:  87.5468909740448\n",
      "Epoca # 19\n",
      "El valor de la función de perdida es:  86.52285933494568\n",
      "Epoca # 20\n",
      "El valor de la función de perdida es:  85.55436134338379\n",
      "Epoca # 21\n",
      "El valor de la función de perdida es:  84.63388681411743\n",
      "Epoca # 22\n",
      "El valor de la función de perdida es:  83.75471830368042\n",
      "Epoca # 23\n",
      "El valor de la función de perdida es:  82.90941119194031\n",
      "Epoca # 24\n",
      "El valor de la función de perdida es:  82.089102268219\n",
      "Epoca # 25\n",
      "El valor de la función de perdida es:  81.28512501716614\n",
      "Epoca # 26\n",
      "El valor de la función de perdida es:  80.49203157424927\n",
      "Epoca # 27\n",
      "El valor de la función de perdida es:  79.70846891403198\n",
      "Epoca # 28\n",
      "El valor de la función de perdida es:  78.93380522727966\n",
      "Epoca # 29\n",
      "El valor de la función de perdida es:  78.16364169120789\n",
      "Epoca # 30\n",
      "El valor de la función de perdida es:  77.39257216453552\n",
      "Epoca # 31\n",
      "El valor de la función de perdida es:  76.62027478218079\n",
      "Epoca # 32\n",
      "El valor de la función de perdida es:  75.84972381591797\n",
      "Epoca # 33\n",
      "El valor de la función de perdida es:  75.08163452148438\n",
      "Epoca # 34\n",
      "El valor de la función de perdida es:  74.31648373603821\n",
      "Epoca # 35\n",
      "El valor de la función de perdida es:  73.55838418006897\n",
      "Epoca # 36\n",
      "El valor de la función de perdida es:  72.8106677532196\n",
      "Epoca # 37\n",
      "El valor de la función de perdida es:  72.07355499267578\n",
      "Epoca # 38\n",
      "El valor de la función de perdida es:  71.3503360748291\n",
      "Epoca # 39\n",
      "El valor de la función de perdida es:  70.64662575721741\n",
      "Epoca # 40\n",
      "El valor de la función de perdida es:  69.96431946754456\n",
      "Epoca # 41\n",
      "El valor de la función de perdida es:  69.30596232414246\n",
      "Epoca # 42\n",
      "El valor de la función de perdida es:  68.67370009422302\n",
      "Epoca # 43\n",
      "El valor de la función de perdida es:  68.06650757789612\n",
      "Epoca # 44\n",
      "El valor de la función de perdida es:  67.48671531677246\n",
      "Epoca # 45\n",
      "El valor de la función de perdida es:  66.93493723869324\n",
      "Epoca # 46\n",
      "El valor de la función de perdida es:  66.41055345535278\n",
      "Epoca # 47\n",
      "El valor de la función de perdida es:  65.91433882713318\n",
      "Epoca # 48\n",
      "El valor de la función de perdida es:  65.44501185417175\n",
      "Epoca # 49\n",
      "El valor de la función de perdida es:  65.0036871433258\n",
      "Epoca # 50\n",
      "El valor de la función de perdida es:  64.58984017372131\n",
      "Epoca # 51\n",
      "El valor de la función de perdida es:  64.2033576965332\n",
      "Epoca # 52\n",
      "El valor de la función de perdida es:  63.84391784667969\n",
      "Epoca # 53\n",
      "El valor de la función de perdida es:  63.5098934173584\n",
      "Epoca # 54\n",
      "El valor de la función de perdida es:  63.199955224990845\n",
      "Epoca # 55\n",
      "El valor de la función de perdida es:  62.91135549545288\n",
      "Epoca # 56\n",
      "El valor de la función de perdida es:  62.64246702194214\n",
      "Epoca # 57\n",
      "El valor de la función de perdida es:  62.39096522331238\n",
      "Epoca # 58\n",
      "El valor de la función de perdida es:  62.155866622924805\n",
      "Epoca # 59\n",
      "El valor de la función de perdida es:  61.935609579086304\n",
      "Epoca # 60\n",
      "El valor de la función de perdida es:  61.72947883605957\n",
      "Epoca # 61\n",
      "El valor de la función de perdida es:  61.536359786987305\n",
      "Epoca # 62\n",
      "El valor de la función de perdida es:  61.355507373809814\n",
      "Epoca # 63\n",
      "El valor de la función de perdida es:  61.186134815216064\n",
      "Epoca # 64\n",
      "El valor de la función de perdida es:  61.027514934539795\n",
      "Epoca # 65\n",
      "El valor de la función de perdida es:  60.87899208068848\n",
      "Epoca # 66\n",
      "El valor de la función de perdida es:  60.73983311653137\n",
      "Epoca # 67\n",
      "El valor de la función de perdida es:  60.60953736305237\n",
      "Epoca # 68\n",
      "El valor de la función de perdida es:  60.48734784126282\n",
      "Epoca # 69\n",
      "El valor de la función de perdida es:  60.37285923957825\n",
      "Epoca # 70\n",
      "El valor de la función de perdida es:  60.26538014411926\n",
      "Epoca # 71\n",
      "El valor de la función de perdida es:  60.16456484794617\n",
      "Epoca # 72\n",
      "El valor de la función de perdida es:  60.069864988327026\n",
      "Epoca # 73\n",
      "El valor de la función de perdida es:  59.98089909553528\n",
      "Epoca # 74\n",
      "El valor de la función de perdida es:  59.89723801612854\n",
      "Epoca # 75\n",
      "El valor de la función de perdida es:  59.81849431991577\n",
      "Epoca # 76\n",
      "El valor de la función de perdida es:  59.74429249763489\n",
      "Epoca # 77\n",
      "El valor de la función de perdida es:  59.6743106842041\n",
      "Epoca # 78\n",
      "El valor de la función de perdida es:  59.60820913314819\n",
      "Epoca # 79\n",
      "El valor de la función de perdida es:  59.54565405845642\n",
      "Epoca # 80\n",
      "El valor de la función de perdida es:  59.4864547252655\n",
      "Epoca # 81\n",
      "El valor de la función de perdida es:  59.430283308029175\n",
      "Epoca # 82\n",
      "El valor de la función de perdida es:  59.376925230026245\n",
      "Epoca # 83\n",
      "El valor de la función de perdida es:  59.32614207267761\n",
      "Epoca # 84\n",
      "El valor de la función de perdida es:  59.2778205871582\n",
      "Epoca # 85\n",
      "El valor de la función de perdida es:  59.23170447349548\n",
      "Epoca # 86\n",
      "El valor de la función de perdida es:  59.18765068054199\n",
      "Epoca # 87\n",
      "El valor de la función de perdida es:  59.14558172225952\n",
      "Epoca # 88\n",
      "El valor de la función de perdida es:  59.10530686378479\n",
      "Epoca # 89\n",
      "El valor de la función de perdida es:  59.066736698150635\n",
      "Epoca # 90\n",
      "El valor de la función de perdida es:  59.02978181838989\n",
      "Epoca # 91\n",
      "El valor de la función de perdida es:  58.99432301521301\n",
      "Epoca # 92\n",
      "El valor de la función de perdida es:  58.960288763046265\n",
      "Epoca # 93\n",
      "El valor de la función de perdida es:  58.927541971206665\n",
      "Epoca # 94\n",
      "El valor de la función de perdida es:  58.89609456062317\n",
      "Epoca # 95\n",
      "El valor de la función de perdida es:  58.86581540107727\n",
      "Epoca # 96\n",
      "El valor de la función de perdida es:  58.836668729782104\n",
      "Epoca # 97\n",
      "El valor de la función de perdida es:  58.80857706069946\n",
      "Epoca # 98\n",
      "El valor de la función de perdida es:  58.78151059150696\n",
      "Epoca # 99\n",
      "El valor de la función de perdida es:  58.75539779663086\n",
      "Epoca # 100\n",
      "El valor de la función de perdida es:  58.73018503189087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6ae3a9e9dd5f>:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer2(x))\n"
     ]
    }
   ],
   "source": [
    "modelo = RegresionLogisticaMulticlase(features_train.shape[1])\n",
    "losses = []\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "epocas = 100\n",
    "\n",
    "x_train, y_train = Variable(torch.from_numpy(features_train)).float(), Variable(torch.from_numpy(labels_train)).long()\n",
    "for epoca in range(1, epocas+1):\n",
    "    print (\"Epoca #\",epoca)\n",
    "    y_pred = modelo(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    print (\"El valor de la función de perdida es: \", loss.item()*100)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() \n",
    "    optimizer.step() \n",
    "    losses.append(loss.item()*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6ae3a9e9dd5f>:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer2(x))\n"
     ]
    }
   ],
   "source": [
    "x_test = Variable(torch.from_numpy(features_test)).float()\n",
    "pred = modelo(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n",
      "Valor Verdadero = 2.0 Valor predecido = 2\n",
      "Valor Verdadero = 1.0 Valor predecido = 1\n",
      "Valor Verdadero = 0.0 Valor predecido = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6ae3a9e9dd5f>:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.layer2(x))\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(x_test)):\n",
    "    y_pred = np.argmax(modelo(x_test[j]).detach().numpy(), axis=0)\n",
    "    print(f'Valor Verdadero = {labels_test[j]} Valor predecido = {y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
